<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="0d"/>







  <link rel="alternate" href="/atom.xml" title="mengyouhan">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.3.x" />



<link rel="canonical" href="mengyouhan.github.io/"/>


<meta name="description" content="0d">
<meta property="og:type" content="website">
<meta property="og:title" content="mengyouhan">
<meta property="og:url" content="mengyouhan.github.io/index.html">
<meta property="og:site_name" content="mengyouhan">
<meta property="og:description" content="0d">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mengyouhan">
<meta name="twitter:description" content="0d">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.3.x" />



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />





<script>
  var CONFIG = {
    search: true,
    searchPath: "/search.xml",
    fancybox: true,
    toc: true,
  }
</script>




  



    <title> mengyouhan </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">mengyouhan</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            简线
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            寻他
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            无法归
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            无我
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">mengyouhan</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              简线
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              寻他
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              无法归
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              无我
            
          </a>
        </li>
      
      
        <li class="menu-search">
          <form>
            <i class="iconfont icon-search" id="open-search"></i>
            <input type="text" class="search-input" id="search-input" />
            <i class="iconfont icon-close" id="close-search"></i>
          </form>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  <section id="posts" class="posts">
    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/05/pypa3/">爬虫的路（3）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月5日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p> 不是工具不好，只是不适合我<br>所以，我要写自己的工具包</p>
</blockquote>
<p>要对人友好，而不是对机器友好<br>
          <div class="read-more">
            <a href="/2017/05/05/pypa3/" class="read-more-link">Read more..</a>
          </div>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/04/2017-05-04/"></a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月4日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <script src="/assets/js/DPlayer.min.js"> </script>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/01/pypa2/">爬虫的路（2）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月1日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <script src="/assets/js/DPlayer.min.js"> </script><blockquote>
<p> 刚开始，什么都没有<br>后来就有了一切</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">headers = &#123;&apos;User-Agent&apos;: UA&#125;</div><div class="line"></div><div class="line">yuanwen_fc = yuanwen.split(&apos;。&apos;)</div><div class="line">url[:-4]+&apos;mp3&apos;</div><div class="line"></div><div class="line"></div><div class="line">str11 = &apos;&apos;&apos;</div><div class="line">-------</div><div class="line">&#123;y&#125;  [沪江小D](&#123;hj&#125;) [単語林](&#123;tangorin&#125;) [jisho](&#123;jisho&#125;) [goo辞书](&#123;goo&#125;) [语调发音](&#123;ojad&#125;) [例句](&#123;lizi&#125;)&lt;br&gt;</div><div class="line">``&#123;chaxun&#125;``</div><div class="line"></div><div class="line">    &apos;&apos;&apos;.format(y=y, hj=hj,tangorin = tangorin,jisho =jisho,goo=goo,ojad=ojad,lizi = lizi,chaxun=chaxun)</div><div class="line">    f.write(str11 + &apos;\n&apos;)</div></pre></td></tr></table></figure>
<p>bs4<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">面向对象尝试</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import requests,os</div><div class="line"></div><div class="line">class SpiderHTML(object):</div><div class="line">    # 打开页面</div><div class="line">    def getUrl(self,url):</div><div class="line">        wb_data = requests.get(url)</div><div class="line">        return BeautifulSoup(wb_data.text, &apos;lxml&apos;)</div><div class="line"></div><div class="line"></div><div class="line">    # 传入图片地址，文件名，保存单张图片</div><div class="line">    def saveImg(self, imageURL, fileName):</div><div class="line">        img = requests.get(imageURL)</div><div class="line">        f = open(fileName, &apos;wb&apos;)  ##写入多媒体文件必须要 b 这个参数！！必须要！！</div><div class="line">        f.write(img.content)  ##多媒体文件要是用conctent哦！</div><div class="line">        f.close()</div><div class="line"></div><div class="line"></div><div class="line">实例化</div><div class="line">pider = doubanDetil(url)</div><div class="line"></div><div class="line"></div><div class="line">select1 = &quot;#overflowbox  font[size=3]&quot;</div><div class="line"></div><div class="line"></div><div class="line">    a1 = [x.get_text() for x in soup.select(select1)]</div><div class="line"></div><div class="line">    for x in soup.find_all(size=&quot;3&quot;):</div><div class="line">            a2.append(x.next_sibling.get_text())</div></pre></td></tr></table></figure></p>
<p>py ku<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">计数</div><div class="line">from collections import Counter</div><div class="line"></div><div class="line"># c = Counter(allM)</div><div class="line"># sss = c.most_common(1000)</div><div class="line">zip</div><div class="line">for imgName,imgURL,findUrl in zip(imgNames,imgURLs,findUrls):</div><div class="line"></div><div class="line"> allM.append(y[&apos;name&apos;])</div><div class="line"></div><div class="line">[1,42,56,523,53,32] + [1,4,56,34,53]</div><div class="line"></div><div class="line">re</div><div class="line">data2 = [re.compile(r&apos;\d+&apos;).search(x.get_text()).group() for x in yeshus]</div><div class="line"></div><div class="line">re.sub(&apos;[ \r\n]&apos;,&apos;&apos;,x)</div><div class="line">niii = &apos;第一章：冰公主..(12p)&apos;</div><div class="line">zhe = re.compile(r&apos;\d+&apos;)</div><div class="line">mo = zhe.search(ni)</div><div class="line">mo.group()</div><div class="line">print(mo.group())</div><div class="line">re.compile(r&apos;\d+&apos;).search(ni).group()</div><div class="line"></div><div class="line"></div><div class="line">f re.split(r&apos;[=&amp;]+&apos;,x)[0] == x:</div><div class="line">      t1 = re.split(r&apos;[/]+&apos;, x)[-2]</div><div class="line">      gid1 = re.split(r&apos;[/]+&apos;, x)[-3]</div><div class="line"></div><div class="line">re.compile(r&apos;(=.&#123;2,10&#125;&amp;)&apos;).findall(x)[0][1:-1]</div><div class="line"></div><div class="line"></div><div class="line">sa = re.sub(r&quot;(&lt;rt&gt;.&#123;1,14&#125;&lt;/rt&gt;)&quot;, &apos;&apos;, str(y)[1:-1])</div><div class="line">su = [x.get_text() for x in soup2][0].strip()</div><div class="line">yuanwen = re.sub(r&quot;\n&quot;, &apos;&apos;, su)</div><div class="line"></div><div class="line">while(j&lt;20):</div><div class="line"></div><div class="line">time</div><div class="line"></div><div class="line">end = time.time()</div><div class="line">print(end - start)</div><div class="line"></div><div class="line"></div><div class="line">if x.get(&apos;title&apos;) != None</div><div class="line"></div><div class="line">os</div><div class="line">song += songlist</div><div class="line">f = open(&apos;/Users/user/Desktop/song.txt&apos;, &apos;a&apos;, encoding=&apos;utf8&apos;)</div><div class="line">with open(&apos;datdsaa.txt&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f:</div><div class="line">    for i in f.readlines():</div><div class="line">        data = json.loads(i)</div><div class="line">        cd_url.insert_one(data)</div><div class="line">        # print(p)</div><div class="line">    # print(f.readlines())</div><div class="line">    # f.write( + &apos;\n&apos;)</div><div class="line">    f.close()</div><div class="line"></div><div class="line">f.write(str(best))</div><div class="line">f.close()</div><div class="line">print(len(best))</div><div class="line"></div><div class="line"></div><div class="line">f.writelines(&apos;&#123;&#125; &#123;&#125;&apos;.format(songlist[0],i)+&apos;\n&apos;)</div><div class="line"></div><div class="line"></div><div class="line">st = time.time()</div><div class="line">time.sleep(random.randint(1, 10))</div><div class="line">time.sleep(random.randint(1, 10))</div><div class="line">end = time.time()</div><div class="line"></div><div class="line">for j in range(1, num + 1):</div><div class="line"></div><div class="line">try:</div></pre></td></tr></table></figure></p>
<p>selenium<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">from selenium import webdriver</div><div class="line">from selenium.webdriver.common.keys import Keys</div><div class="line"></div><div class="line">driver = webdriver.PhantomJS()</div><div class="line"></div><div class="line">driver.get(&quot;http://www.u17.com/chapter/266667.html#image_id=1911641&quot;)</div><div class="line">print(driver.page_source)</div><div class="line"></div><div class="line"># driver = webdriver.Chrome()</div><div class="line"># driver.get(&apos;https://www.baidu.com/&apos;)</div><div class="line"># elem = driver.find_element_by_id(&apos;kw&apos;)</div><div class="line"># elem.send_keys(&apos;爬虫&apos;)</div><div class="line"># elem.send_keys(Keys.RETURN)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># driver = webdriver.Chrome()</div><div class="line"># driver.get(&apos;http://www.jianshu.com/p/520749be7377&apos;)</div><div class="line"># time.sleep(1)</div><div class="line"># for i in range(10):</div><div class="line">#     driver.execute_script(&apos;window.scrollTo(0,document.body.scrollHeight)&apos;)</div><div class="line">#     time.sleep(1)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># driver2.get(url)</div><div class="line">  # driver2.delete_all_cookies()</div><div class="line">  # for cookx in cook:</div><div class="line">  #     driver2.add_cookie(cookx)</div><div class="line"></div><div class="line">driver2.switch_to.frame(&quot;g_iframe&quot;)</div><div class="line"></div><div class="line">driver.switch_to.frame(&quot;g_iframe&quot;)</div><div class="line">  soup = BeautifulSoup(driver.page_source, &apos;lxml&apos;)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">  def soups(url):</div><div class="line">      driver = webdriver.PhantomJS()</div><div class="line">      driver.get(url)</div><div class="line">      driver.delete_all_cookies()</div><div class="line">      for i in cook:</div><div class="line">          driver.add_cookie(i)</div><div class="line">      driver.get(url)</div><div class="line">      soup = BeautifulSoup(driver.page_source, &apos;lxml&apos;)</div><div class="line">      return soup</div><div class="line"></div><div class="line">self.driver.switch_to_window(self.driver.window_handles[1])</div><div class="line">    time.sleep(12)</div><div class="line">    self.driver.switch_to.frame(&quot;dic&quot;)</div><div class="line">    soup = BeautifulSoup(self.driver.page_source, &apos;lxml&apos;)</div><div class="line"></div><div class="line">driver.delete_all_cookies()</div><div class="line">for cookx in cook:</div><div class="line">    driver.add_cookie(cookx)</div><div class="line"></div><div class="line">driver.get(url)</div><div class="line">time.sleep(10)</div><div class="line"></div><div class="line">aa = driver.page_source</div><div class="line"></div><div class="line">self.driver.find_element_by_css_selector(&quot;#monthly &gt; div &gt; ul &gt; li:nth-child(2)&quot;).click()</div></pre></td></tr></table></figure></p>
<p>xpath</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">publish_date = [x.text for x in res.getxpath(str(soup)).xpath(&apos;//tr[@class=&quot;gtr0&quot;]/td[2]&apos;)]</div><div class="line">  favarate_date = [x.text for x in res.getxpath(str(soup)).xpath(&apos;//tr[@class=&quot;gtr0&quot;]/td[4]&apos;)]</div><div class="line"></div><div class="line">//*[@id=&quot;subject_list&quot;]/ul/li[1]/div[2]/h2/a</div></pre></td></tr></table></figure>
<p>pq<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">from pyquery import PyQuery as pq</div><div class="line">url = &apos;http://music.163.com/#/discover/playlist/?cat=%E6%80%A7%E6%84%9F&apos;</div><div class="line">d = pq(url=url, headers=&#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36&quot;&#125;)</div><div class="line">img_tag = d(&quot;a&quot;)</div><div class="line"># for info in img_tag:</div><div class="line">#     print(d(info).attr(&quot;src&quot;))</div><div class="line">print(d)</div></pre></td></tr></table></figure></p>
<p>mongodb<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd_url.update(&#123;&apos;url&apos;:url&#125;,&#123;&apos;$set&apos;:</div><div class="line">                                 &#123;&apos;price&apos;: &apos;19&apos;,</div><div class="line">                                  &apos;need&apos;: &apos;职位描述：岗位职责：1、参与公司产品项目需求的技术评审及设计；2、完成个人所负责模块&apos;,</div><div class="line">                                  &apos;name&apos;: &apos;秋声科技拉勾未认证企业&apos;</div><div class="line">                                  &#125;&#125;)</div></pre></td></tr></table></figure></p>
<p>例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">cd_url = mongo.pymg(&apos;lagou&apos;,&apos;cd_url&apos;)</div><div class="line">def get_dtails(url):</div><div class="line">    select1 = &apos;div.position-head div.position-content-l  p span.salary&apos;</div><div class="line">    select2 = &apos;#job_detail &gt; dd.job_bt&apos;</div><div class="line">    select3 = &apos;#job_detail &gt; dd.job-address.clearfix&apos;</div><div class="line">    select4 = &apos;#job_company &gt; dt &gt; a &gt; div &gt; h2&apos;</div><div class="line"></div><div class="line">    price = res.get_select(url,select=select1)</div><div class="line">    need = res.get_select(url,select=select2)</div><div class="line">    address= res.get_select(url,select=select3)</div><div class="line">    name = res.get_select(url,select=select4)</div><div class="line">    re_price = re.sub(&apos;[ \r\n]&apos;, &apos;&apos;, price[0].get_text())</div><div class="line">    re_need = re.sub(&apos;[ \r\n]&apos;, &apos;&apos;, need[0].get_text())</div><div class="line">    re_address = re.sub(&apos;[ \r\n]&apos;, &apos;&apos;, address[0].get_text())</div><div class="line">    re_name = re.sub(&apos;[ \r\n]&apos;, &apos;&apos;, name[0].get_text())</div><div class="line">    return [re_price,re_need,re_address,re_name]</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">for i in cd_url.find():</div><div class="line">    url = i[&apos;url&apos;]</div><div class="line">    try:</div><div class="line">        basedata = get_dtails(url)</div><div class="line">        data = &#123;</div><div class="line">            &apos;price&apos;: basedata[0],</div><div class="line">            &apos;need&apos;: basedata[1],</div><div class="line">            &apos;address&apos;: basedata[2],</div><div class="line">            &apos;company&apos;: basedata[3],</div><div class="line">            &apos;status&apos;: 1</div><div class="line">        &#125;</div><div class="line">        cd_url.update(&#123;&apos;url&apos;:url&#125;,&#123;&apos;$set&apos;:data&#125;)</div><div class="line">        time.sleep(1)</div><div class="line">        print(&apos;_____________&apos;)</div><div class="line">    except:</div><div class="line">        exceptdata = &#123;</div><div class="line">            &apos;status&apos;: 0</div><div class="line">        &#125;</div><div class="line">        cd_url.update(&#123;&apos;url&apos;:url&#125;,&#123;&apos;$set&apos;:exceptdata&#125;)</div><div class="line">        print(&apos;解析插入数据库失败&apos;)</div></pre></td></tr></table></figure></p>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/01/pypa1/">爬虫的路（起步）</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月1日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <script src="/assets/js/DPlayer.min.js"> </script><blockquote>
<p> 刚开始，什么都没有<br>后来就有了一切</p>
</blockquote>
<p>编辑器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">ctr+1(Pycharm编辑器)create class如何调出</div></pre></td></tr></table></figure></p>
<p>今天时间属于爬虫<br>刚开始requests<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">range(2,40,1)</div><div class="line"></div><div class="line">headers = &#123;&#125;</div><div class="line">requests.get(url_cookie,headers=headers)   .content  .text  .json</div></pre></td></tr></table></figure></p>
<p>用bs4<br>select<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">soup = BeautifulSoup(wb_data.text,&apos;lxml&apos;)</div><div class="line">imgs = soup.select(&apos;ul.user-list &gt; li &gt; a &gt; img&apos;)</div><div class="line"></div><div class="line">all_a = Soup.find(&apos;div&apos;, class_=&apos;all&apos;).find_all(&apos;a&apos;)  ##意思是先查找 class为 all 的div标签，然后查找所有的&lt;a&gt;标签。</div><div class="line">max_span = html_Soup.find_all(&apos;span&apos;)[10].get_text()  ##查找所有的&lt;span&gt;标签获取第十个的&lt;span&gt;标签中的文本也就是最后一个</div><div class="line">img_url = img_Soup.find(&apos;div&apos;, class_=&apos;main-image&apos;).find(&apos;img&apos;)[&apos;src&apos;]  ##这三行上面都说过啦不解释了哦</div><div class="line"></div><div class="line">link = soup.find(&apos;a&apos;,href=&apos;http://live.bilibili.com&apos;)</div><div class="line">print(link.name,link[&apos;href&apos;],link.get_text())</div><div class="line"></div><div class="line"></div><div class="line">ather = i.get(&apos;alt&apos;)</div><div class="line">  img_url = i.get(&apos;src&apos;)</div><div class="line">  path = str(ather).strip()</div></pre></td></tr></table></figure></p>
<p>技巧<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&apos;https://www.zhihu.com/collection/132331007?page=&#123;&#125;&apos;.format(page)</div><div class="line">xx = [y[&apos;href&apos;] for y in title if y[&apos;href&apos;][0] == &apos;/&apos;]</div><div class="line">listQ += xx</div><div class="line">[&apos;https://www.zhihu.com/&apos;+i for i in listQ]</div></pre></td></tr></table></figure></p>
<p>不好用 nth 不支持<br>lxml 封装</p>
<p>os<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">os.makedirs(os.path.join(&quot;/Users/user/Desktop/pypy/cs&quot;, path))</div><div class="line">  os.chdir(&quot;/Users/user/Desktop/pypy/cs/&quot; + path)</div><div class="line"></div><div class="line">  f = open(name + &apos;.jpg&apos;, &apos;ab&apos;)  ##写入多媒体文件必须要 b 这个参数！！必须要！！</div><div class="line">    f.write(img.content)  ##多媒体文件要是用conctent哦！</div><div class="line">    f.close()</div><div class="line"></div><div class="line"></div><div class="line">    def text_create(name, msg):</div><div class="line">        desktop_path = &apos;/Users/user/Desktop/&apos;</div><div class="line">        full_path = desktop_path + name + &apos;.txt&apos;</div><div class="line">        file = open(full_path,&apos;w&apos;)</div><div class="line">        file.write(msg)</div><div class="line">        file.close()</div><div class="line">        print(&apos;Done&apos;)</div><div class="line">    text_create(&apos;hello&apos;,&apos;hello world&apos;)</div></pre></td></tr></table></figure></p>
<p>学会保存到本地<br>文件读写</p>
<p>动态网页 下载漫画<br>su</p>
<p>微博 服务器<br>异地登录的话 要手滑验证码<br>cookie<br>那时候还不会数据库<br>每分钟执行一次 查看最新微博<br>用一个txt文件来缓存信息</p>
<p>到后来<br>TXT的读写<br>格式都不是很好用</p>
<p>每次爬虫还不能断<br>断了数据就没了<br>就使用了mongodb</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># $lt/$lte/$gt/$gte/$ne，依次等价于&lt;/&lt;=/&gt;/&gt;=/!=。（l表示less g表示greater e表示equal n表示not  ）</div><div class="line">for item in sheet_tab.find(&#123;&apos;words&apos;:&#123;&apos;$lt&apos;:10&#125;&#125;):</div><div class="line">    print(item)</div></pre></td></tr></table></figure>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/01/pypa/">爬虫的路(总)</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月1日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <script src="/assets/js/DPlayer.min.js"> </script><blockquote>
<p> 有些路回首时，已经走了</p>
</blockquote>
<p>编辑器</p>
<p>用bs4<br>select</p>
<p>不好用 nth 不支持<br>lxml 封装</p>
<p>os</p>
<p>学会保存到本地<br>文件读写</p>
<p>动态网页 下载漫画<br>su</p>
<p>微博 服务器<br>异地登录的话 要手滑验证码<br>cookie<br>那时候还不会数据库<br>每分钟执行一次 查看最新微博<br>用一个txt文件来缓存信息</p>
<p>到后来<br>TXT的读写<br>格式都不是很好用</p>
<p>每次爬虫还不能断<br>断了数据就没了<br>就使用了mongodb</p>
<p>爬 总会有各种意外 互虐意外 try<br>虽然存到了数据库里面<br>但怎么样解决 爬取过的就不要再爬了呢</p>
<p>后来我就 没爬过的设置成 status——0 给爬过的为1</p>
<p>即使爬虫断了 下次直接重新运行再运行一下爬虫就可以了<br>不用再做其他的<br>find({‘status’:0})</p>
<p>当爬取的数据有点多，一时半会爬不完<br>电脑一直开着不好，晚上12点会断电<br>本地运行爬虫就不太合适了，<br>于是我在服务器上运行<br>但是我是通过ssh连接到服务器了<br>一旦shh断开<br>我的爬虫也就停止了<br>和本机上没有什么区别<br>我知道了有定时任务这个东西<br>我真实个天才<br>每3分钟运行一次<br>一旦开始运行<br>取消定时任务<br>后来我有发现 还是经常断<br>而且每次这样操作台麻烦了<br>我又发现了 nohup<br>其实我早就知道了 nohup的<br>只是我当时用过没有生效<br>现在我才知道 当时是因为当时没有在后面加 &amp;<br>坑啊<br>走了这么久的弯路<br>使用 pstree也可以很方便的查看进程状态</p>
<p>即使这样<br>还是会发现还是要断<br>py error<br>比以前要好</p>
<p>我知道有个叫supers<br>的进程守护<br>这就是我下一步要做的事情</p>
<p>还有个问题<br>效率<br>有些程序 即使我不使用多线程 也没到多久就封IP了<br>所以还是要先解决封ip问题<br>2个思路<br>1.自己维护一个代理池<br>爬虫没有再提升，这是很大一部分原因<br>2，使用多台机器<br>我做过的就是<br>给爬的数据index 比如我有3台机器<br>我就把前1/3的分给1台机器<br>分开运行 和在一台机器上运行 没什么区别<br>我还是使用着time.sleep<br>不断探索着 保持着不被封IP</p>
<p>最近我要爬的数据有60多万个网页<br>而且在国内被墙的<br>而我只有一台国外的服务器<br>使用着time.sleep<br>和 断<br>现在才爬到30多万</p>
<p>现在要做的就是 IP池 最好还有国外的 GitHub上有一个 可以先去看看<br>分布式 其实我已经做了分布式<br>但是 用队列是一个更好的方式</p>
<p>IP问题解决了 多进程 多线程 协程才有意义</p>
<p>redis 解决了<br>super 解决了 才不用受</p>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/01/next1/">下一阶段</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月1日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <script src="/assets/js/DPlayer.min.js"> </script><blockquote>
<p> 我们总会遇到重复的问题</p>
</blockquote>
<p>爬虫方面<br>请求获取源代码<br>1.request<br>2.su 自动登录获取cookies</p>
<p>常用的正则表达式</p>
<p>分析提取网页<br>一个数据或者一组数据</p>
<p>提前规划好提取字段 数据存储格式 使用数据库</p>
<p>存储数据</p>
<p>约定大于配置</p>
<p>不要重复</p>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/05/01/sum1/">为什么总结很重要</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年5月1日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p> 我们总会遇到重复的问题</p>
</blockquote>
<p>dash spnnit 代码片段<br>抽象成函数 类 包<br>记录下详细流程 下次直接看 如包的安装<br>印象笔记 quiver 知识储存<br>博客 总结 </p>
          <div class="read-more">
            <a href="/2017/05/01/sum1/" class="read-more-link">Read more..</a>
          </div>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/04/30/do1/">4/30/2017 申请了小程序开发者</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年4月30日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>做了些之前一直准备做而没有做的事</p>
</blockquote>
<p>申请了小程序开发者<br>发现播放音乐<br>缓存<br>终于把网址拿去备案了<br>有个网址总比IP地址好一些<br>虽然初审还是有问题<br>
          <div class="read-more">
            <a href="/2017/04/30/do1/" class="read-more-link">Read more..</a>
          </div>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/04/29/hexo2/">dplayer 在hexo中插入视频</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年4月29日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p><a href="https://github.com/NextMoe/hexo-tag-dplayer">hexo-tag-dplayer github 地址</a></p>
</blockquote>
          <div class="read-more">
            <a href="/2017/04/29/hexo2/" class="read-more-link">Read more..</a>
          </div>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2017/04/28/py_php/">语言学习框架与项目</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2017年4月28日
        </span>
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        
          
        

        
          <blockquote>
<p>Python到PHP的转移 过渡</p>
</blockquote>
<h2 id="项目驱动-过去的Python项目翻译成PHP"><a href="#项目驱动-过去的Python项目翻译成PHP" class="headerlink" title="项目驱动 过去的Python项目翻译成PHP"></a>项目驱动 过去的Python项目翻译成PHP</h2>
          <div class="read-more">
            <a href="/2017/04/28/py_php/" class="read-more-link">Read more..</a>
          </div>
        
      
    </div>

    

    

  </article>

    
  </section>

  
  <nav class="pagination">
    
    
      <a class="next" href="/page/2/">
        <span class="next-text">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


          </div>
          

        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/mengyouhan" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/megyouhan/answers" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
    
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
    
    2017

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">mengyouhan</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.3.x"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.3.x"></script>

    
  <script type="text/html" id="search-result">
    <article class="post">
      <header class="post-header">
        <h1 class="post-title">
          <a href="$url$" class="post-link">
            $title$
          </a>
        </h1>
      </header>
      <div class="post-content">
        $content$
        <div class="read-more">
          <a href="$url$" class="read-more-link">
            Read more..
          </a>
        </div>
      </div>
    </article>
  </script>
  <script type="text/html" id="no-search-result">
    <div class="no-result">
      <h2>No result found!</h2>
    </div>
  </script>
  <script type="text/javascript" src="/js/src/search.js?v=2.3.x"></script>

  </body>
</html>
